"""
ç‹¬ç«‹æµè§ˆå™¨æŠ“å–æœåŠ¡

ä¸€ä¸ªæ”¯æŒé«˜å¹¶å‘çš„ç½‘é¡µæŠ“å–æœåŠ¡ï¼Œä½¿ç”¨ Playwright å®ç°ã€‚
æ¯ä¸ªè¯·æ±‚ä½¿ç”¨ç‹¬ç«‹çš„æµè§ˆå™¨å®ä¾‹ï¼Œç¡®ä¿çœŸæ­£çš„å¹¶å‘å¤„ç†ã€‚
"""
import asyncio
import logging
import os
import random
import re
import time
import psutil
from contextlib import asynccontextmanager
from typing import Any

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from playwright.async_api import async_playwright, Browser, async_playwright
from playwright_stealth import Stealth
from markdownify import markdownify

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# ==================== é…ç½® ====================

class Config:
    """æœåŠ¡é…ç½®"""

    # æœåŠ¡é…ç½®
    PORT = int(os.getenv('BROWSER_SERVICE_PORT', '2025'))
    HOST = os.getenv('BROWSER_SERVICE_HOST', '0.0.0.0')

    # æµè§ˆå™¨é…ç½®
    POOL_SIZE = int(os.getenv('BROWSER_POOL_SIZE', '5'))
    MAX_CONCURRENT_PAGES = int(os.getenv('MAX_CONCURRENT_PAGES', '10'))
    HEADLESS = os.getenv('HEADLESS', 'true').lower() == 'true'
    MAX_SCREENSHOT_SIZE = int(os.getenv('MAX_SCREENSHOT_SIZE', '5242880'))

    # User-Agent æ± 
    USER_AGENTS = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15",
    ]

    # æµè§ˆå™¨å¯åŠ¨å‚æ•°
    BROWSER_ARGS = [
        '--no-sandbox',
        '--disable-dev-shm-usage',
        '--disable-blink-features=AutomationControlled',
        '--disable-gpu',
        '--disable-extensions',
        '--disable-background-networking',
        '--disable-default-apps',
        '--disable-sync',
        '--no-first-run',
        '--disable-setuid-sandbox',
    ]

    @classmethod
    def get_random_user_agent(cls) -> str:
        """è·å–éšæœº User-Agent"""
        return random.choice(cls.USER_AGENTS)


# ==================== è¯·æ±‚/å“åº”æ¨¡å‹ ====================

class FetchRequest(BaseModel):
    """æŠ“å–è¯·æ±‚"""
    url: str
    wait_time: int = 200  # ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    wait_for_selector: str = ""  # ç­‰å¾…é€‰æ‹©å™¨
    screenshot: bool = True  # æ˜¯å¦æˆªå›¾


class FetchResponse(BaseModel):
    """æŠ“å–å“åº”"""
    success: bool
    fetched_url: str
    title: str = ""
    content: str = ""
    screenshot: str = ""  # base64 ç¼–ç 
    content_length: int = 0
    fetched_at: str = ""
    error: str = ""
    duration_seconds: float = 0  # æŠ“å–è€—æ—¶ï¼ˆç§’ï¼‰


# ==================== å†…å­˜ç›‘æ§å·¥å…· ====================

def get_memory_info() -> dict[str, Any]:
    """è·å–å½“å‰è¿›ç¨‹å†…å­˜ä¿¡æ¯"""
    process = psutil.Process(os.getpid())
    mem_info = process.memory_info()

    # è·å–æ‰€æœ‰å­è¿›ç¨‹ï¼ˆChromium è¿›ç¨‹ï¼‰
    children = process.children(recursive=True)
    children_mem = 0
    chromium_count = 0

    for child in children:
        try:
            child_mem = child.memory_info().rss
            children_mem += child_mem
            # æ£€æŸ¥æ˜¯å¦æ˜¯ Chromium è¿›ç¨‹
            if 'chrom' in child.name().lower() or 'chrome' in child.name().lower():
                chromium_count += 1
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            pass

    return {
        "process_rss_mb": round(mem_info.rss / 1024 / 1024, 2),
        "process_vms_mb": round(mem_info.vms / 1024 / 1024, 2),
        "children_rss_mb": round(children_mem / 1024 / 1024, 2),
        "total_rss_mb": round((mem_info.rss + children_mem) / 1024 / 1024, 2),
        "chromium_processes": chromium_count,
        "total_children": len(children),
    }


def format_bytes(bytes_value: int) -> str:
    """æ ¼å¼åŒ–å­—èŠ‚æ•°ä¸ºå¯è¯»æ ¼å¼"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if bytes_value < 1024.0:
            return f"{bytes_value:.2f} {unit}"
        bytes_value /= 1024.0
    return f"{bytes_value:.2f} TB"


# ==================== æµè§ˆå™¨å®ä¾‹æ±  ====================

class BrowserPool:
    """æµè§ˆå™¨å®ä¾‹æ± """

    def __init__(self, pool_size: int):
        self.pool_size = pool_size
        self.browsers: list[Browser] = []
        self.playwright = None
        self.semaphore = asyncio.Semaphore(pool_size)
        self._initialized = False
        self._request_count = 0  # è¯·æ±‚è®¡æ•°å™¨
        self._start_time = time.time()  # å¯åŠ¨æ—¶é—´
        self._stealth = Stealth()  # å¤ç”¨ Stealth å®ä¾‹
        self._fetch_counts = [0] * pool_size  # æ¯ä¸ªæµè§ˆå™¨çš„æŠ“å–è®¡æ•°
        self._restart_threshold = 20  # æ¯æŠ“å– 20 æ¬¡é‡å¯æµè§ˆå™¨

    async def initialize(self):
        """åˆå§‹åŒ–æµè§ˆå™¨æ± """
        if self._initialized:
            return

        logger.info(f"åˆå§‹åŒ–æµè§ˆå™¨å®ä¾‹æ± ï¼Œå¤§å°: {self.pool_size}")

        try:
            self.playwright = await async_playwright().start()

            # å¯åŠ¨å¤šä¸ªæµè§ˆå™¨å®ä¾‹
            for i in range(self.pool_size):
                browser = await self.playwright.chromium.launch(
                    headless=Config.HEADLESS,
                    args=Config.BROWSER_ARGS
                )
                self.browsers.append(browser)
                logger.info(f"æµè§ˆå™¨å®ä¾‹ {i}: å·²å¯åŠ¨")

            self._initialized = True
            logger.info(f"æµè§ˆå™¨å®ä¾‹æ± åˆå§‹åŒ–å®Œæˆï¼Œå®ä¾‹æ•°: {len(self.browsers)}")

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æµè§ˆå™¨æ± å¤±è´¥: {e}")
            raise

    async def shutdown(self):
        """å…³é—­æ‰€æœ‰æµè§ˆå™¨å®ä¾‹"""
        logger.info("å…³é—­æµè§ˆå™¨å®ä¾‹æ± ...")

        for i, browser in enumerate(self.browsers):
            try:
                await browser.close()
                logger.info(f"æµè§ˆå™¨å®ä¾‹ {i}: å·²å…³é—­")
            except Exception as e:
                logger.warning(f"å…³é—­æµè§ˆå™¨å®ä¾‹ {i} æ—¶å‡ºé”™: {e}")

        self.browsers.clear()

        if self.playwright:
            try:
                await self.playwright.stop()
                logger.info("Playwright å·²åœæ­¢")
            except Exception as e:
                logger.warning(f"åœæ­¢ Playwright æ—¶å‡ºé”™: {e}")

        self._initialized = False

    async def fetch_page(self, request: FetchRequest) -> FetchResponse:
        """ä»æ± ä¸­è·å–ä¸€ä¸ªæµè§ˆå™¨å®ä¾‹æ¥æŠ“å–é¡µé¢"""
        if not self._initialized:
            await self.initialize()

        self._request_count += 1
        start_time = time.time()

        # å†…å­˜ç›‘æ§ä»»åŠ¡
        monitor_task = None
        stop_monitor = asyncio.Event()

        async def monitor_memory():
            """å¼‚æ­¥ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ"""
            while not stop_monitor.is_set():
                mem_info = get_memory_info()
                logger.info(
                    f"ğŸ“Š [æŠ“å–ä¸­] RSS: {mem_info['process_rss_mb']:.1f}MB | "
                    f"å­è¿›ç¨‹: {mem_info['children_rss_mb']:.1f}MB | "
                    f"æ€»è®¡: {mem_info['total_rss_mb']:.1f}MB"
                )
                try:
                    await asyncio.wait_for(stop_monitor.wait(), timeout=2.0)
                except asyncio.TimeoutError:
                    continue

        async with self.semaphore:
            # è·å–ä¸€ä¸ªå¯ç”¨çš„æµè§ˆå™¨å®ä¾‹ï¼ˆè½®è¯¢ï¼‰
            browser_index = id(asyncio.current_task()) % len(self.browsers)
            browser = self.browsers[browser_index]

            context = None
            page = None

            try:
                # å¯åŠ¨å†…å­˜ç›‘æ§
                monitor_task = asyncio.create_task(monitor_memory())

                # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
                context = await browser.new_context(
                    viewport={"width": 1920, "height": 1080},
                    user_agent=Config.get_random_user_agent(),
                )

                page = await context.new_page()

                # æš‚æ—¶ç¦ç”¨åçˆ¬è™«ï¼ˆå¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼ï¼‰
                # await self._apply_stealth(page)

                # è®¾ç½®è¯·æ±‚å¤´
                await page.set_extra_http_headers(self._get_headers())

                # å¯¼èˆªåˆ°é¡µé¢
                await page.goto(request.url, wait_until="commit", timeout=30000)

                # ç­‰å¾…æŒ‡å®šæ—¶é—´
                if request.wait_time > 0:
                    await page.wait_for_timeout(request.wait_time)

                # ç­‰å¾…é€‰æ‹©å™¨
                if request.wait_for_selector:
                    await page.wait_for_selector(request.wait_for_selector, timeout=10000)

                # è·å–å†…å®¹
                title = await page.title()
                html_content = await page.content()

                # å¼‚æ­¥è½¬æ¢ä¸º Markdownï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
                markdown_content = await asyncio.to_thread(markdownify, html_content)
                cleaned_content = self._clean_markdown(markdown_content)

                # æˆªå›¾
                screenshot_b64 = ""
                if request.screenshot:
                    screenshot_bytes = await page.screenshot(full_page=False)
                    if len(screenshot_bytes) <= Config.MAX_SCREENSHOT_SIZE:
                        import base64
                        screenshot_b64 = base64.b64encode(screenshot_bytes).decode()

                duration_seconds = time.time() - start_time

                return FetchResponse(
                    success=True,
                    fetched_url=request.url,
                    title=title or "æ— æ ‡é¢˜",
                    content=cleaned_content,
                    screenshot=screenshot_b64,
                    content_length=len(cleaned_content),
                    fetched_at=time.strftime("%Y-%m-%d %H:%M:%S"),
                    duration_seconds=duration_seconds
                )

            except Exception as e:
                logger.error(f"æŠ“å–å¤±è´¥ {request.url}: {e}")
                duration_seconds = time.time() - start_time
                return FetchResponse(
                    success=False,
                    fetched_url=request.url,
                    error=str(e),
                    duration_seconds=duration_seconds
                )

            finally:
                # åœæ­¢å†…å­˜ç›‘æ§
                stop_monitor.set()
                if monitor_task:
                    try:
                        await asyncio.wait_for(monitor_task, timeout=0.5)
                    except (asyncio.TimeoutError, asyncio.CancelledError):
                        pass

                # å½»åº•å…³é—­é¡µé¢å’Œä¸Šä¸‹æ–‡
                if page:
                    try:
                        await page.close()
                        # ç§»é™¤å¼•ç”¨ï¼Œå¸®åŠ© GC
                        page = None
                    except:
                        page = None

                if context:
                    try:
                        # ç­‰å¾…æ‰€æœ‰èµ„æºé‡Šæ”¾
                        await context.close()
                        # ç§»é™¤å¼•ç”¨ï¼Œå¸®åŠ© GC
                        context = None
                    except:
                        context = None

                # å¼ºåˆ¶åƒåœ¾å›æ”¶
                import gc
                gc.collect()

                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯æµè§ˆå™¨
                self._fetch_counts[browser_index] += 1
                if self._fetch_counts[browser_index] >= self._restart_threshold:
                    logger.info(f"æµè§ˆå™¨ {browser_index} å·²æŠ“å– {self._fetch_counts[browser_index]} æ¬¡ï¼Œæ‰§è¡Œé‡å¯...")
                    self._fetch_counts[browser_index] = 0
                    try:
                        await browser.close()
                        new_browser = await self.playwright.chromium.launch(
                            headless=Config.HEADLESS,
                            args=Config.BROWSER_ARGS
                        )
                        self.browsers[browser_index] = new_browser
                        logger.info(f"æµè§ˆå™¨ {browser_index} é‡å¯å®Œæˆ")
                    except Exception as e:
                        logger.error(f"é‡å¯æµè§ˆå™¨ {browser_index} å¤±è´¥: {e}")

    async def _apply_stealth(self, page):
        """åº”ç”¨åçˆ¬è™«è„šæœ¬"""
        await self._stealth.apply_stealth_async(page)

    def _get_headers(self) -> dict[str, str]:
        """è·å–è¯·æ±‚å¤´"""
        return {
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "DNT": "1",
        }

    def _clean_markdown(self, content: str) -> str:
        """æ¸…ç† Markdown"""
        content = re.sub(r'\n{3,}', '\n\n', content)
        content = re.sub(r'^\s+$/gm', '', content)
        return content.strip()


# ==================== å…¨å±€å®ä¾‹æ±  ====================

_browser_pool: BrowserPool | None = None


def get_browser_pool() -> BrowserPool:
    """è·å–æµè§ˆå™¨å®ä¾‹æ± ï¼ˆå•ä¾‹ï¼‰"""
    global _browser_pool
    if _browser_pool is None:
        pool_size = Config.POOL_SIZE
        _browser_pool = BrowserPool(pool_size)
    return _browser_pool


# ==================== FastAPI åº”ç”¨ ====================

app = FastAPI(
    title="Browser Fetch Service",
    description="ç‹¬ç«‹çš„ç½‘é¡µæŠ“å–æœåŠ¡ï¼Œæ”¯æŒé«˜å¹¶å‘",
    version="1.0.0"
)


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "Browser Fetch Service",
        "version": "1.0.0",
        "status": "running",
        "pool_size": Config.POOL_SIZE,
    }


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    pool = get_browser_pool()
    mem_info = get_memory_info()

    # è®¡ç®—è¿è¡Œæ—¶é—´
    uptime = time.time() - pool._start_time if pool._start_time else 0

    return {
        "status": "healthy",
        "browser_started": pool._initialized,
        "pool_size": Config.POOL_SIZE,
        "max_concurrent": Config.MAX_CONCURRENT_PAGES,
        "request_count": pool._request_count,
        "uptime_seconds": round(uptime, 2),
        "memory": mem_info,
    }


@app.get("/stats")
async def stats():
    """è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
    pool = get_browser_pool()
    mem_info = get_memory_info()

    # è®¡ç®—è¿è¡Œæ—¶é—´
    uptime = time.time() - pool._start_time if pool._start_time else 0

    # ç³»ç»Ÿä¿¡æ¯
    sys_mem = psutil.virtual_memory()
    sys_cpu = psutil.cpu_percent(interval=0.1)

    return {
        "service": {
            "name": "Browser Fetch Service",
            "version": "1.0.0",
            "uptime_seconds": round(uptime, 2),
            "request_count": pool._request_count,
            "requests_per_second": round(pool._request_count / uptime, 2) if uptime > 0 else 0,
        },
        "browser_pool": {
            "pool_size": Config.POOL_SIZE,
            "max_concurrent": Config.MAX_CONCURRENT_PAGES,
            "initialized": pool._initialized,
            "active_browsers": len(pool.browsers),
        },
        "memory": {
            "process_mb": mem_info["process_rss_mb"],
            "children_mb": mem_info["children_rss_mb"],
            "total_mb": mem_info["total_rss_mb"],
            "chromium_processes": mem_info["chromium_processes"],
            "total_children": mem_info["total_children"],
        },
        "system": {
            "cpu_percent": sys_cpu,
            "memory_total_gb": round(sys_mem.total / 1024 / 1024 / 1024, 2),
            "memory_available_gb": round(sys_mem.available / 1024 / 1024 / 1024, 2),
            "memory_percent": sys_mem.percent,
        },
    }


@app.get("/metrics")
async def metrics():
    """Prometheus é£æ ¼çš„ç›‘æ§æŒ‡æ ‡"""
    pool = get_browser_pool()
    mem_info = get_memory_info()

    uptime = time.time() - pool._start_time if pool._start_time else 0

    metrics_text = f"""# HELP browser_service_requests_total Total number of requests
# TYPE browser_service_requests_total counter
browser_service_requests_total {pool._request_count}

# HELP browser_service_uptime_seconds Service uptime in seconds
# TYPE browser_service_uptime_seconds gauge
browser_service_uptime_seconds {uptime:.2f}

# HELP browser_service_pool_size Browser pool size
# TYPE browser_service_pool_size gauge
browser_service_pool_size {Config.POOL_SIZE}

# HELP browser_service_memory_bytes Total memory usage in bytes
# TYPE browser_service_memory_bytes gauge
browser_service_memory_bytes {mem_info["total_rss_mb"] * 1024 * 1024}

# HELP browser_service_chromium_processes Number of Chromium processes
# TYPE browser_service_chromium_processes gauge
browser_service_chromium_processes {mem_info["chromium_processes"]}

# HELP browser_service_max_concurrent Maximum concurrent pages per browser
# TYPE browser_service_max_concurrent gauge
browser_service_max_concurrent {Config.MAX_CONCURRENT_PAGES}
"""

    from fastapi.responses import Response
    return Response(
        content=metrics_text,
        media_type="text/plain",
    )


@app.post("/fetch")
async def fetch_page(request: FetchRequest):
    """
    æŠ“å–ç½‘é¡µå†…å®¹

    Args:
        request: æŠ“å–è¯·æ±‚

    Returns:
        æŠ“å–ç»“æœ
    """
    pool = get_browser_pool()
    result = await pool.fetch_page(request)
    return result


@app.post("/fetch_url")
async def fetch_url(
    request: FetchRequest
):
    """
    æŠ“å–ç½‘é¡µå¹¶è¿”å›å†…å®¹

    Args:
        request: æŠ“å–è¯·æ±‚

    Returns:
        åŒ…å« Markdown å†…å®¹å’Œæˆªå›¾çš„æŠ“å–ç»“æœ
    """
    pool = get_browser_pool()
    result = await pool.fetch_page(request)

    if not result.success:
        return result

    # ç›´æ¥è¿”å›å†…å­˜ä¸­çš„æ•°æ®ï¼Œä¸ç”Ÿæˆä¸´æ—¶æ–‡ä»¶
    return {
        "success": True,
        "fetched_url": result.fetched_url,
        "title": result.title,
        "markdown_content": result.content,
        "screenshot_base64": result.screenshot,
        "content_length": result.content_length,
        "fetched_at": result.fetched_at,
        "duration_seconds": result.duration_seconds
    }


# ==================== ç”Ÿå‘½å‘¨æœŸç®¡ç† ====================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–æµè§ˆå™¨æ± 
    pool = get_browser_pool()
    await pool.initialize()
    logger.info("æµè§ˆå™¨æœåŠ¡å·²å°±ç»ª")

    yield

    # å…³é—­æ—¶æ¸…ç†
    await pool.shutdown()
    logger.info("æµè§ˆå™¨æœåŠ¡å·²å…³é—­")


app.router.lifespan_context = lifespan

# å¯¼å‡º app ä¾› uvicorn ä½¿ç”¨
__all__ = ["app"]
